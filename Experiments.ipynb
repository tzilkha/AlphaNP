{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Diz6TXlgXmxB"
   },
   "source": [
    "# Class Exercise - MCTS with TSP\n",
    "- Tal Zilkha - tiz2102\n",
    "- Mat Hillman - mh3691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXkT460PXmxK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "EPS = 1e-8\n",
    "import copy\n",
    "\n",
    "class MCTS():\n",
    "    \"\"\"\n",
    "    This class handles the MCTS tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, nnet, args):\n",
    "        self.game = game\n",
    "        self.nnet = nnet\n",
    "        self.args = args\n",
    "        self.Qsa = {}       # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores #times edge s,a was visited\n",
    "        self.Ns = {}        # stores #times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "        self.Es = {}        # stores game.getGameEnded ended for board s\n",
    "        self.Vs = {}        # stores game.getValidMoves for board s\n",
    "        \n",
    "        self.val = [float('inf')]\n",
    "        self.num_sim = [0]\n",
    "\n",
    "    def getActionProb(self, state, temp=1):\n",
    "        \"\"\"\n",
    "        This function performs numMCTSSims simulations of MCTS starting from\n",
    "        canonicalBoard.\n",
    "        Returns:\n",
    "            probs: a policy vector where the probability of the ith action is\n",
    "                   proportional to Nsa[(s,a)]**(1./temp)\n",
    "        \"\"\"\n",
    "        for i in range(self.args.numMCTSSims):\n",
    "            self.search(state, i)\n",
    "\n",
    "        s = self.game.stringRepresentation(state[-1])\n",
    "        counts = [self.Nsa[(s,a)] if (s,a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "        \n",
    "        if temp==0:\n",
    "            bestA = np.argmax(counts)\n",
    "            probs = [0]*len(counts)\n",
    "            probs[bestA]=1\n",
    "            return probs\n",
    "\n",
    "        counts = [x**(1./temp) for x in counts]\n",
    "        counts_sum = float(sum(counts))\n",
    "        probs = [x/counts_sum for x in counts]\n",
    "        return probs\n",
    "\n",
    "\n",
    "    def search(self, state, num_sim):\n",
    "        \"\"\"\n",
    "        This function performs one iteration of MCTS. It is recursively called\n",
    "        till a leaf node is found. The action chosen at each node is one that\n",
    "        has the maximum upper confidence bound as in the paper.\n",
    "        Once a leaf node is found, the neural network is called to return an\n",
    "        initial policy P and a value v for the state. This value is propagated\n",
    "        up the search path. In case the leaf node is a terminal state, the\n",
    "        outcome is propagated up the search path. The values of Ns, Nsa, Qsa are\n",
    "        updated.\n",
    "        NOTE: the return values are the negative of the value of the current\n",
    "        state. This is done since v is in [-1,1] and if v is the value of a\n",
    "        state for the current player, then its value is -v for the other player.\n",
    "        Returns:\n",
    "            v: the negative of the value of the current canonicalBoard\n",
    "        \"\"\"\n",
    "\n",
    "        s = self.game.stringRepresentation(state[-1])\n",
    "        \n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.game.getGameEnded(state[-1])\n",
    "        if self.Es[s]!=0:\n",
    "            # terminal node\n",
    "            return 0\n",
    "\n",
    "        if s not in self.Ps:\n",
    "            # leaf node\n",
    "            if self.nnet is not None:\n",
    "                if args['history']:\n",
    "                    self.Ps[s], v = self.nnet.predict(state, self.game.graph)\n",
    "                else:\n",
    "                    self.Ps[s], v = self.nnet.predict(state[-1], self.game.graph)\n",
    "            else:\n",
    "                self.Ps[s] = np.ones(self.game.getActionSize()) # random policy\n",
    "                v = 0\n",
    "            valids = self.game.getValidMoves(state[-1])\n",
    "            self.Ps[s] = self.Ps[s]*valids      # masking invalid moves\n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s    # renormalize\n",
    "            else:\n",
    "                # if all valid moves were masked make all valid moves equally probable\n",
    "                \n",
    "                # NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                print(\"All valid moves were masked, do workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Vs[s] = valids\n",
    "            self.Ns[s] = 0\n",
    "            return v\n",
    "\n",
    "        valids = self.Vs[s]\n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        for a in range(self.game.getActionSize()):\n",
    "            if valids[a]:\n",
    "                if (s,a) in self.Qsa:\n",
    "                    u = self.Qsa[(s,a)] + self.args.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s])/(1+self.Nsa[(s,a)])\n",
    "                else:\n",
    "                    u = self.args.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s] + EPS)     # Q = 0 ?\n",
    "\n",
    "                if u > cur_best:\n",
    "                    cur_best = u\n",
    "                    best_act = a\n",
    "\n",
    "        a = best_act\n",
    "        next_s, reward = self.game.getNextState(state[-1], a)\n",
    "        new_history = copy.deepcopy(state)\n",
    "        new_history.append(next_s)\n",
    "        \n",
    "        v = self.search(new_history, num_sim) + reward\n",
    "        \n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)]*self.Qsa[(s,a)] + v)/(self.Nsa[(s,a)]+1)\n",
    "            self.Nsa[(s,a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v\n",
    "            self.Nsa[(s,a)] = 1\n",
    "            \n",
    "        if self.game.getActionSize() - self.val[-1] < v:\n",
    "            self.val += [self.game.getActionSize() - v]\n",
    "            self.num_sim += [num_sim]\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2ruv-kiXmyS"
   },
   "source": [
    "# TSPGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMskmQ-aXmyZ"
   },
   "outputs": [],
   "source": [
    "from itertools import permutations \n",
    "\n",
    "class TSPGame():\n",
    "    \"\"\"\n",
    "    This class specifies the base Game class. To define your own game, subclass\n",
    "    this class and implement the functions below. This works when the game is\n",
    "    two-player, adversarial and turn-based.\n",
    "    Use 1 for player1 and -1 for player2.\n",
    "    See othello/OthelloGame.py for an example implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.num_node = args.num_node\n",
    "        self.graph = np.random.rand(self.num_node, 2)\n",
    "\n",
    "    def getStartState(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            start_state: a representation of the graph\n",
    "        \"\"\"\n",
    "        start_state = np.zeros([self.num_node, 2])\n",
    "        start_state[0,0] = 1\n",
    "        start_state[0,1] = 1\n",
    "        return start_state\n",
    "\n",
    "    def getActionSize(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            self.num_node: number of all possible actions\n",
    "        \"\"\"\n",
    "        return self.num_node\n",
    "\n",
    "    def getNextState(self, state, action):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            state: current state\n",
    "            action: action taken by current player\n",
    "        Returns:\n",
    "            next_state: graph after applying action\n",
    "            reward: reward from action\n",
    "        \"\"\"\n",
    "        next_state = state.copy()\n",
    "        next_state[:, 1] = 0\n",
    "        next_state[action, :] = 1\n",
    "        prev_action = np.where(state[:, 1] == 1)[0][0]\n",
    "        prev_node = self.graph[prev_action]\n",
    "        cur_node = self.graph[action]\n",
    "        reward = 1 - np.linalg.norm(cur_node - prev_node)\n",
    "        if self.num_node == np.sum(next_state[:, 0]):\n",
    "            reward += 1 - np.linalg.norm(cur_node - self.graph[0])\n",
    "            \n",
    "        return next_state, reward\n",
    "\n",
    "    def getValidMoves(self, state):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            state: current state\n",
    "        Returns:\n",
    "            1 - state[:, 0]: a binary vector of length self.getActionSize(), 1 for\n",
    "                            moves that are valid from the current board and player,\n",
    "                            0 for invalid moves\n",
    "        \"\"\"\n",
    "        return 1 - state[:, 0]\n",
    "\n",
    "    def getGameEnded(self, state):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            state: current board state\n",
    "        Returns:\n",
    "            r: 0 if game has not ended. 1 if it has\n",
    "               \n",
    "        \"\"\"\n",
    "        r = 0\n",
    "        if self.num_node == np.sum(state[:, 0]):\n",
    "            r = 1\n",
    "        return r\n",
    "\n",
    "    def stringRepresentation(self, state):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            state: current state\n",
    "        Returns:\n",
    "            s: string representation of state\n",
    "        \"\"\"\n",
    "        s = ''\n",
    "        for i in range(self.num_node):\n",
    "            s += str(int(state[i, 0]))\n",
    "        return s\n",
    "    \n",
    "    def optimal_sol(self):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            \n",
    "        Returns:\n",
    "            optimal_val: optimal solution for TSP\n",
    "            optimal_path: optimal path for TSP\n",
    "        \"\"\"\n",
    "        cur_reward = 0\n",
    "        optimal_val = float('inf')\n",
    "        optimal_path = []\n",
    "        graph = self.graph\n",
    "\n",
    "        nodes = np.arange(self.num_node)[1:]\n",
    "        perms = permutations(nodes)\n",
    "        \n",
    "        for perm in list(perms):\n",
    "            cur_reward = 0\n",
    "            \n",
    "            cur_reward += np.linalg.norm(graph[0] - graph[perm[0]])\n",
    "            for i in range(len(perm) - 1):\n",
    "                j = perm[i]\n",
    "                k = perm[i+1]\n",
    "                cur_reward += np.linalg.norm(graph[k] - graph[j])\n",
    "            cur_reward += np.linalg.norm(graph[perm[-1]] - graph[0])\n",
    "            \n",
    "            if optimal_val > cur_reward:\n",
    "                optimal_val = cur_reward\n",
    "                optimal_path = perm\n",
    "        \n",
    "        return optimal_val, optimal_path\n",
    "    \n",
    "    def create_sample(self):\n",
    "        path = self.optimal_sol()[1]+tuple([0])\n",
    "        current = self.getStartState()\n",
    "        samples_v = []\n",
    "        samples_pi = []\n",
    "        tot_v = 0\n",
    "        for i in path:\n",
    "            pi = np.zeros(self.getActionSize())\n",
    "            pi[i] = 1\n",
    "            samples_pi.append((current, pi))\n",
    "            next, v = self.getNextState(current, i)\n",
    "            samples_v.append((current, v))\n",
    "            current = next\n",
    "        \n",
    "        return samples_v, samples_pi\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77NUtw5kXm1G"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HSZvnyHXm1P"
   },
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "args = dotdict({\n",
    "    # State representation\n",
    "    'history': True,           # Whether state representation should be a history of states - used for lstm\n",
    "    'history_length': None,     # If None full history\n",
    "    \n",
    "    # MCTS args\n",
    "    'numMCTSSims': 500,        # Number of games moves for MCTS to simulate.\n",
    "    'num_node': 7,              # Number of nodes in the graph (game)\n",
    "    \n",
    "    # Train args\n",
    "    'numIters': 1,              # Number of episods to play (5 times 10 episodes)\n",
    "    'numEps': 1,                # Number of complete self-play games to simulate during a new iteration.\n",
    "    'tempThreshold': 15,        #\n",
    "    'updateThreshold': 0.6,     # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
    "    'maxlenOfQueue': 200000,    # Number of game examples to train the neural networks.\n",
    "    'arenaCompare': 40,         # Number of games to play during arena play to determine if new net will be accepted.\n",
    "    'cpuct': 1,\n",
    "    'numItersForTrainExamplesHistory': 25,\n",
    "    \n",
    "    # NN args\n",
    "    'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 64,\n",
    "    'cuda': False,\n",
    "    'num_channels': 512,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbBUNyajXm11"
   },
   "source": [
    "# Self Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHGbBLtlXm12"
   },
   "outputs": [],
   "source": [
    "def play_game(args):\n",
    "    game = TSPGame(args)\n",
    "    mcts = MCTS(game, None, args)\n",
    "    state = [game.getStartState()]\n",
    "    mcts_reward = 0\n",
    "    mcts_actions = []\n",
    "    optimal_val, optimal_path = game.optimal_sol()\n",
    "    while not game.getGameEnded(state[-1]):\n",
    "        action = np.argmax(mcts.getActionProb(state))\n",
    "        next_state, reward = game.getNextState(state[-1], action)\n",
    "        state.append(next_state)\n",
    "        mcts_actions += [action]\n",
    "        mcts_reward += reward\n",
    "        \n",
    "#     print('Optimal Solution:', optimal_val)\n",
    "#     print('Optimal Action:', optimal_path)\n",
    "#     print('MCTS Reward:', game.getActionSize() - mcts_reward)\n",
    "#     print('MCTS Action:', mcts_actions)\n",
    "    \n",
    "    return mcts.val, mcts.num_sim, optimal_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6VCBNzSXm2i"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "1Xps_DamXm2n",
    "outputId": "89057f4e-788f-4276-f40d-2ec93cf15322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 192, 192] [inf, 6.954028717293984, 6.365908149869855, 6.204589783654861, 5.760434948576108, 5.214586432099917, 4.781852115764927, 4.383845747692088, 4.222527381477094, 3.5884355313469496, 3.447847120221989, 2.8137552700918445]\n"
     ]
    }
   ],
   "source": [
    "val, num_sim, optimal_reward = play_game(args)\n",
    "print(num_sim, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "URpz55pLXm3Z",
    "outputId": "b508f33b-de74-46b4-d7e4-a715645069ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Length')"
      ]
     },
     "execution_count": 1506,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.array(num_sim[1:]), val[1:])\n",
    "plt.hlines(optimal_reward, 0, num_sim[-1])\n",
    "plt.xlabel(\"Number of Simulations\")\n",
    "plt.ylabel(\"Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import deque\n",
    "# import time, os, sys\n",
    "# from pickle import Pickler, Unpickler\n",
    "# from random import shuffle\n",
    "\n",
    "\n",
    "# class Coach():\n",
    "#     \"\"\"\n",
    "#     This class executes the self-play + learning. It uses the functions defined\n",
    "#     in Game and NeuralNet. args are specified in main.py.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, game, nnet, args):\n",
    "#         self.game = game\n",
    "#         self.nnet = nnet\n",
    "#         self.args = args\n",
    "#         self.mcts = MCTS(self.game, self.nnet, self.args)\n",
    "#         self.trainExamplesHistory = []    # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "#         self.skipFirstSelfPlay = False    # can be overriden in loadTrainExamples()\n",
    "\n",
    "#     def executeEpisode(self):\n",
    "#         \"\"\"\n",
    "#         This function executes one episode of self-play, starting with player 1.\n",
    "#         As the game is played, each turn is added as a training example to\n",
    "#         trainExamples. The game is played till the game ends. After the game\n",
    "#         ends, the outcome of the game is used to assign values to each example\n",
    "#         in trainExamples.\n",
    "\n",
    "#         It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "#         uses temp=0.\n",
    "\n",
    "#         Returns:\n",
    "#             trainExamples: a list of examples of the form (canonicalBoard,pi,v)\n",
    "#                            pi is the MCTS informed policy vector, v is +1 if\n",
    "#                            the player eventually won the game, else -1.\n",
    "#         \"\"\"\n",
    "#         trainExamples = []\n",
    "#         board = [self.game.getStartState()]\n",
    "#         episodeStep = 0\n",
    "\n",
    "#         while True:\n",
    "#             episodeStep += 1\n",
    "#             temp = int(episodeStep < self.args.tempThreshold)\n",
    "\n",
    "#             pi = self.mcts.getActionProb(board, temp=temp)\n",
    "\n",
    "#             action = np.random.choice(len(pi), p=pi)\n",
    "#             next_board, reward = self.game.getNextState(board[-1], action)\n",
    "            \n",
    "#             trainExamples.append([board, self.game.graph, pi, reward])\n",
    "            \n",
    "#             board.append(next_board)\n",
    "            \n",
    "#             r = self.game.getGameEnded(board[-1])\n",
    "            \n",
    "#             if r!=0:\n",
    "#                 return [tuple(x) for x in trainExamples]\n",
    "            \n",
    "#     def learn(self):\n",
    "#         \"\"\"\n",
    "#         Performs numIters iterations with numEps episodes of self-play in each\n",
    "#         iteration. After every iteration, it retrains neural network with\n",
    "#         examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "#         It then pits the new neural network against the old one and accepts it\n",
    "#         only if it wins >= updateThreshold fraction of games.\n",
    "#         \"\"\"\n",
    "#         for i in range(1, self.args.numIters+1):\n",
    "\n",
    "#             if not self.skipFirstSelfPlay or i>1:\n",
    "#                 iterationTrainExamples = deque([], maxlen=self.args.maxlenOfQueue)\n",
    "\n",
    "#                 for eps in range(self.args.numEps):\n",
    "#                     self.mcts = MCTS(self.game, self.nnet, self.args)   # reset search tree\n",
    "#                     iterationTrainExamples += self.executeEpisode()\n",
    "\n",
    "#                 self.trainExamplesHistory.append(iterationTrainExamples)\n",
    "                \n",
    "#             if len(self.trainExamplesHistory) > self.args.numItersForTrainExamplesHistory:\n",
    "#                 print(\"len(trainExamplesHistory) =\", len(self.trainExamplesHistory), \" => remove the oldest trainExamples\")\n",
    "#                 self.trainExamplesHistory.pop(0)\n",
    "\n",
    "#             # shuffle examples before training\n",
    "#             trainExamples = []\n",
    "#             for e in self.trainExamplesHistory:\n",
    "#                 trainExamples.extend(e)\n",
    "#             shuffle(trainExamples)\n",
    "            \n",
    "#         return trainExamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWO89Uw8mnTW"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiQOBbM6mnTr"
   },
   "outputs": [],
   "source": [
    "# Inputs are in the form of a merged matrix of the graph and board\n",
    "\n",
    "class ConvolutionalNN():\n",
    "    def __init__(self, args):\n",
    "        self.action_size = args['num_node']\n",
    "        self.create_net()\n",
    "        # Conv no history\n",
    "        self.args = args\n",
    "        self.args['history'] = False\n",
    "\n",
    "    def train(self, examples):\n",
    "        \"\"\"\n",
    "        examples: list of examples, each example is of form (board, pi, v)\n",
    "        \"\"\"\n",
    "        print(\"Training...\")\n",
    "        input_boards, input_graphs, target_pis, target_vs = list(zip(*examples))\n",
    "        input_boards = np.asarray([boards[-1] for boards in input_boards])\n",
    "        input_graphs = np.asarray(input_graphs)\n",
    "        target_pis = np.asarray(target_pis)\n",
    "        target_vs = np.asarray(target_vs)\n",
    "        \n",
    "        boards_graphs_list = [(input_graphs[i], input_boards[i]) for i in range(0, len(input_boards))] \n",
    "        input = [np.concatenate([*i], axis=1) for i in boards_graphs_list]\n",
    "        self.model.fit(x = [input], y = [target_pis, target_vs], \n",
    "                       batch_size = args.batch_size, epochs = args.epochs, verbose=1)\n",
    "\n",
    "    def predict(self, board, graph):\n",
    "        \"\"\"\n",
    "        board: np array with board\n",
    "        \"\"\"        \n",
    "        merged = np.concatenate([graph, board], axis=1)\n",
    "        merged = merged[np.newaxis, :, :]\n",
    "        \n",
    "        # run\n",
    "        pi, v = self.model.predict(merged)\n",
    "        return pi[0], v[0]\n",
    "    \n",
    "    def create_net(self):\n",
    "        # Neural Net\n",
    "        self.input_boards = Input(shape=(self.action_size, 4))    # s: batch_size x board_x x board_y\n",
    "\n",
    "        x_image = Reshape((self.action_size, 4, 1))(self.input_boards)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='same')(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='same')(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='same')(h_conv2)))        # batch_size  x (board_x) x (board_y) x num_channels\n",
    "        h_conv4 = Activation('relu')(BatchNormalization(axis=3)(Conv2D(args.num_channels, 2, padding='valid')(h_conv3)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4_flat = Flatten()(h_conv4)       \n",
    "        s_fc1 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = Dropout(args.dropout)(Activation('relu')(BatchNormalization(axis=1)(Dense(512)(s_fc1))))          # batch_size x 1024\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(s_fc2)   # batch_size x self.action_size\n",
    "        self.v = Dense(1, activation='relu', name='v')(s_fc2)                    # batch_size x 1\n",
    "\n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))\n",
    "         \n",
    "    def save_model(self, filename):\n",
    "        model_json = self.model.to_json()\n",
    "        with open('saved_models/' + filename + \".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "        # serialize weights to HDF5\n",
    "        self.model.save_weights('saved_models/' + filename + \".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "    def load_model(self, filename):\n",
    "        # load json and create model\n",
    "        json_file = open('saved_models/' + filename + '.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        \n",
    "        # load weights into new model\n",
    "        self.model.load_weights('saved_models/' + filename + \".h5\")\n",
    "        print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "class RecurrentNN():\n",
    "    def __init__(self, args):\n",
    "        # game params\n",
    "        self.action_size = args['num_node']\n",
    "        self.num_node = args['num_node']\n",
    "        self.board_size = (args['num_node'],2)\n",
    "        self.args = args\n",
    "        self.create_net()\n",
    "        # Conv no history\n",
    "        self.args['history'] = True\n",
    "        \n",
    "    def create_net(self):\n",
    "        self.input_boards = Input(shape=(self.num_node, self.num_node*4))\n",
    "        lstm = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(self.input_boards)\n",
    "        dense = Dense(128, activation='sigmoid')(lstm)\n",
    "        self.pi = Dense(self.action_size, activation='softmax', name='pi')(dense)\n",
    "        self.v = Dense(1, activation='relu', name='v')(dense)\n",
    "        \n",
    "        self.model = Model(inputs=self.input_boards, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=Adam(args.lr))        \n",
    "\n",
    "    def predict(self, board_list, graph):\n",
    "        input = self.prepare_input(board_list,graph)\n",
    "        pi, v = self.model.predict(input)\n",
    "\n",
    "\n",
    "        #print('PREDICTION TIME TAKEN : {0:03f}'.format(time.time()-start))\n",
    "        return pi[0], v[0]\n",
    "    \n",
    "    def train(self, examples):\n",
    "        \"\"\"\n",
    "        examples: list of examples, each example is of form (board, pi, v)\n",
    "        \"\"\"\n",
    "        print(\"Training...\")\n",
    "        input_boards, input_graphs, target_pis, target_vs = list(zip(*examples))\n",
    "        input_boards = np.asarray(input_boards)\n",
    "        input_graphs = np.asarray(input_graphs)\n",
    "        target_pis = np.asarray(target_pis)\n",
    "        target_vs = np.asarray(target_vs)\n",
    "        boards_graphs_list = [(input_boards[i], input_graphs[i]) for i in range(0, len(input_boards))] \n",
    "        prepared_inputs = np.asarray([self.prepare_input(*i)[0] for i in boards_graphs_list])\n",
    "        self.model.fit(x = [prepared_inputs], y = [target_pis, target_vs], \n",
    "                       batch_size = args.batch_size, epochs = args.epochs, verbose=1)\n",
    "\n",
    "    #\n",
    "    # State representation is a history of states with the graph appended to them and the whole thing shaped to array.\n",
    "    #\n",
    "    #      [graph, visited, camefrom]  t0\n",
    "    #      [graph, visited, camefrom]  t1\n",
    "    #      [graph, visited, camefrom]  t2\n",
    "    #      ..\n",
    "    #      ..\n",
    "    #      [graph, visited, camefrom]  tn\n",
    "    #\n",
    "    # Where tn is the current state and any timestamp that came before the first move is as such\n",
    "    #      \n",
    "    #      [graph,0,0]\n",
    "    #\n",
    "    \n",
    "    def prepare_input(self,board_list, graph):\n",
    "        if self.args['history_length'] is None:\n",
    "            self.args['history_length'] = self.num_node\n",
    "        while len(board_list)<self.args['history_length']:\n",
    "            board_list = [np.zeros(self.board_size)] + board_list\n",
    "        board_list = [x.transpose() for x in board_list]\n",
    "        input = np.array(board_list).reshape(len(board_list), self.num_node*2)\n",
    "        [graph]*self.num_node\n",
    "        graph_data = np.array(([np.array(graph).reshape(self.num_node*2)]*len(board_list))).reshape(len(board_list), self.num_node*2)\n",
    "        input = np.stack((np.array(graph_data), np.array(input)), axis=1).reshape(1,self.num_node,self.num_node*4)\n",
    "        return(input)\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        model_json = self.model.to_json()\n",
    "        with open('saved_models/' + filename + \".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "        # serialize weights to HDF5\n",
    "        self.model.save_weights('saved_models/' + filename + \".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "    def load_model(self, filename):\n",
    "        # load json and create model\n",
    "        json_file = open('saved_models/' + filename + '.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        \n",
    "        # load weights into new model\n",
    "        self.model.load_weights('saved_models/' + filename + \".h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def play_game_with_nn(args, nn):\n",
    "#     game = TSPGame(args)\n",
    "#     mcts = MCTS(game, nn, args)\n",
    "#     state = [game.getStartState()]\n",
    "#     mcts_reward = 0\n",
    "#     mcts_actions = []\n",
    "#     optimal_val, optimal_path = game.optimal_sol()\n",
    "    \n",
    "#     while not game.getGameEnded(state[-1]):\n",
    "#         action = np.argmax(mcts.getActionProb(state))\n",
    "#         next_state, reward = game.getNextState(state[-1], action)\n",
    "#         state+=[next_state]\n",
    "#         mcts_actions += [action]\n",
    "#         mcts_reward += reward\n",
    "        \n",
    "# #     print('Optimal Solution:', optimal_val)\n",
    "# #     print('Optimal Action:', optimal_path)\n",
    "# #     print('MCTS Reward:', game.getActionSize() - mcts_reward)\n",
    "# #     print('MCTS Action:', mcts_actions)\n",
    "    \n",
    "#     return mcts.val, mcts.num_sim, optimal_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training dataset\n",
    "def create_training_set(args, n_games = 100):\n",
    "    data_set = []\n",
    "    for i in range(n_games):\n",
    "        t = TSPGame(args)\n",
    "        train_v, train_pi = t.create_sample()\n",
    "        for i in range(1,len(train_v)):\n",
    "            boards = [j[0] for j in train_v[:i]]\n",
    "            graph = t.graph\n",
    "            data_set+=[(boards, graph, train_pi[i-1][1], train_v[i-1][1])]\n",
    "    return data_set\n",
    "            \n",
    "dataset = create_training_set(args, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 1.5003 - pi_loss: 1.2786 - v_loss: 0.2218\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 1.1825 - pi_loss: 1.1250 - v_loss: 0.0576\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 1.1610 - pi_loss: 1.1073 - v_loss: 0.0537\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 1.1501 - pi_loss: 1.0982 - v_loss: 0.0519\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 1.1420 - pi_loss: 1.0913 - v_loss: 0.0507\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 1.1364 - pi_loss: 1.0863 - v_loss: 0.0501\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 1.1282 - pi_loss: 1.0782 - v_loss: 0.0500\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 1.1204 - pi_loss: 1.0711 - v_loss: 0.0493\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 1.1093 - pi_loss: 1.0600 - v_loss: 0.0493\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 1.0953 - pi_loss: 1.0460 - v_loss: 0.0493\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 1.0791 - pi_loss: 1.0303 - v_loss: 0.0488\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 1.0652 - pi_loss: 1.0163 - v_loss: 0.0489\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 1.0453 - pi_loss: 0.9966 - v_loss: 0.0487\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 1.0298 - pi_loss: 0.9816 - v_loss: 0.0483\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 1.0175 - pi_loss: 0.9692 - v_loss: 0.0483\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 1.0063 - pi_loss: 0.9583 - v_loss: 0.0480\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.9920 - pi_loss: 0.9439 - v_loss: 0.0481\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.9730 - pi_loss: 0.9253 - v_loss: 0.0478\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.9580 - pi_loss: 0.9104 - v_loss: 0.0477\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.9510 - pi_loss: 0.9035 - v_loss: 0.0476\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.9321 - pi_loss: 0.8847 - v_loss: 0.0474\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.9231 - pi_loss: 0.8757 - v_loss: 0.0474\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.9105 - pi_loss: 0.8634 - v_loss: 0.0471\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.8996 - pi_loss: 0.8527 - v_loss: 0.0469\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.8889 - pi_loss: 0.8417 - v_loss: 0.0472\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.8832 - pi_loss: 0.8365 - v_loss: 0.0466\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.8728 - pi_loss: 0.8261 - v_loss: 0.0467\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.8674 - pi_loss: 0.8206 - v_loss: 0.0467\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.8586 - pi_loss: 0.8121 - v_loss: 0.0464\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.8510 - pi_loss: 0.8046 - v_loss: 0.0464\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.8428 - pi_loss: 0.7964 - v_loss: 0.0464\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.8373 - pi_loss: 0.7910 - v_loss: 0.0463\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.8308 - pi_loss: 0.7849 - v_loss: 0.0459\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.8223 - pi_loss: 0.7764 - v_loss: 0.0459\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.8185 - pi_loss: 0.7728 - v_loss: 0.0458\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.8127 - pi_loss: 0.7672 - v_loss: 0.0455\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.8121 - pi_loss: 0.7665 - v_loss: 0.0456\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.8050 - pi_loss: 0.7595 - v_loss: 0.0455\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.7976 - pi_loss: 0.7523 - v_loss: 0.0453\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.7987 - pi_loss: 0.7535 - v_loss: 0.0452\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7924 - pi_loss: 0.7477 - v_loss: 0.0447\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7898 - pi_loss: 0.7450 - v_loss: 0.0449\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7862 - pi_loss: 0.7414 - v_loss: 0.0448\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7833 - pi_loss: 0.7384 - v_loss: 0.0449\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7770 - pi_loss: 0.7321 - v_loss: 0.0448\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7708 - pi_loss: 0.7263 - v_loss: 0.0445\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.7678 - pi_loss: 0.7232 - v_loss: 0.0446\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7669 - pi_loss: 0.7227 - v_loss: 0.0442\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7598 - pi_loss: 0.7154 - v_loss: 0.0444\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7589 - pi_loss: 0.7147 - v_loss: 0.0442\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.7515 - pi_loss: 0.7075 - v_loss: 0.0440\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.7520 - pi_loss: 0.7079 - v_loss: 0.0441\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.7482 - pi_loss: 0.7043 - v_loss: 0.0439\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7422 - pi_loss: 0.6983 - v_loss: 0.0439\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7407 - pi_loss: 0.6970 - v_loss: 0.0437\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.7384 - pi_loss: 0.6946 - v_loss: 0.0437\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7351 - pi_loss: 0.6914 - v_loss: 0.0437\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7317 - pi_loss: 0.6882 - v_loss: 0.0435 0s - loss: 0.7314 - pi\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.7342 - pi_loss: 0.6906 - v_loss: 0.0436\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.7267 - pi_loss: 0.6836 - v_loss: 0.0431\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.7240 - pi_loss: 0.6805 - v_loss: 0.0436\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7208 - pi_loss: 0.6775 - v_loss: 0.0434\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7202 - pi_loss: 0.6770 - v_loss: 0.0432\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7164 - pi_loss: 0.6733 - v_loss: 0.0431\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.7151 - pi_loss: 0.6716 - v_loss: 0.0434\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.7125 - pi_loss: 0.6694 - v_loss: 0.0431\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7091 - pi_loss: 0.6660 - v_loss: 0.0431\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.7078 - pi_loss: 0.6649 - v_loss: 0.0429\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.7031 - pi_loss: 0.6598 - v_loss: 0.0433\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.7041 - pi_loss: 0.6611 - v_loss: 0.0430\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.7048 - pi_loss: 0.6620 - v_loss: 0.0428\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.7010 - pi_loss: 0.6580 - v_loss: 0.0430\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 60s 998us/step - loss: 0.6966 - pi_loss: 0.6538 - v_loss: 0.0428\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6940 - pi_loss: 0.6512 - v_loss: 0.0428\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6940 - pi_loss: 0.6514 - v_loss: 0.0426\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6877 - pi_loss: 0.6452 - v_loss: 0.0425\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.6881 - pi_loss: 0.6455 - v_loss: 0.0426\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6904 - pi_loss: 0.6480 - v_loss: 0.0424\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6864 - pi_loss: 0.6437 - v_loss: 0.0426\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6869 - pi_loss: 0.6444 - v_loss: 0.0425\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6837 - pi_loss: 0.6410 - v_loss: 0.0427\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6810 - pi_loss: 0.6387 - v_loss: 0.0423\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6787 - pi_loss: 0.6365 - v_loss: 0.0422\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6794 - pi_loss: 0.6369 - v_loss: 0.0424\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6760 - pi_loss: 0.6336 - v_loss: 0.0424\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6771 - pi_loss: 0.6349 - v_loss: 0.0422\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6720 - pi_loss: 0.6297 - v_loss: 0.0423\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6726 - pi_loss: 0.6300 - v_loss: 0.0426\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6683 - pi_loss: 0.6258 - v_loss: 0.0425\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6665 - pi_loss: 0.6244 - v_loss: 0.0421\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.6615 - pi_loss: 0.6196 - v_loss: 0.0420\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 60s 998us/step - loss: 0.6659 - pi_loss: 0.6236 - v_loss: 0.0423\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6659 - pi_loss: 0.6237 - v_loss: 0.0422\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6630 - pi_loss: 0.6211 - v_loss: 0.0419\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6588 - pi_loss: 0.6168 - v_loss: 0.0420\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6587 - pi_loss: 0.6167 - v_loss: 0.0420\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6593 - pi_loss: 0.6172 - v_loss: 0.0421\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6598 - pi_loss: 0.6178 - v_loss: 0.0420 1s -\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6538 - pi_loss: 0.6119 - v_loss: 0.0420\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6548 - pi_loss: 0.6130 - v_loss: 0.0418\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6528 - pi_loss: 0.6109 - v_loss: 0.0419\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6462 - pi_loss: 0.6044 - v_loss: 0.0418\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6502 - pi_loss: 0.6088 - v_loss: 0.0414\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6494 - pi_loss: 0.6074 - v_loss: 0.0420\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6475 - pi_loss: 0.6054 - v_loss: 0.0420\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6469 - pi_loss: 0.6051 - v_loss: 0.0418\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.6450 - pi_loss: 0.6031 - v_loss: 0.0419\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6471 - pi_loss: 0.6055 - v_loss: 0.0416\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6427 - pi_loss: 0.6009 - v_loss: 0.0417 1s\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6381 - pi_loss: 0.5964 - v_loss: 0.0417\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6379 - pi_loss: 0.5964 - v_loss: 0.0414\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6408 - pi_loss: 0.5991 - v_loss: 0.0418\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6371 - pi_loss: 0.5954 - v_loss: 0.0417\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.6357 - pi_loss: 0.5941 - v_loss: 0.0416\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6353 - pi_loss: 0.5938 - v_loss: 0.0415\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6336 - pi_loss: 0.5921 - v_loss: 0.0416\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6314 - pi_loss: 0.5902 - v_loss: 0.0412\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6319 - pi_loss: 0.5904 - v_loss: 0.0415\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6293 - pi_loss: 0.5877 - v_loss: 0.0416\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6274 - pi_loss: 0.5860 - v_loss: 0.0414\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6278 - pi_loss: 0.5863 - v_loss: 0.0415\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6257 - pi_loss: 0.5843 - v_loss: 0.0414\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6235 - pi_loss: 0.5821 - v_loss: 0.0414\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6263 - pi_loss: 0.5849 - v_loss: 0.0414\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6236 - pi_loss: 0.5824 - v_loss: 0.0413\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6188 - pi_loss: 0.5775 - v_loss: 0.0412\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6209 - pi_loss: 0.5796 - v_loss: 0.0413\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6204 - pi_loss: 0.5788 - v_loss: 0.0416\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.6197 - pi_loss: 0.5783 - v_loss: 0.0414\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6231 - pi_loss: 0.5816 - v_loss: 0.0414\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6156 - pi_loss: 0.5743 - v_loss: 0.0413\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6153 - pi_loss: 0.5743 - v_loss: 0.0410\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6134 - pi_loss: 0.5720 - v_loss: 0.0414\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6156 - pi_loss: 0.5742 - v_loss: 0.0413\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6120 - pi_loss: 0.5710 - v_loss: 0.0411\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6120 - pi_loss: 0.5705 - v_loss: 0.0415\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6076 - pi_loss: 0.5664 - v_loss: 0.0412\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.6064 - pi_loss: 0.5654 - v_loss: 0.0411\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6113 - pi_loss: 0.5701 - v_loss: 0.0413\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6079 - pi_loss: 0.5669 - v_loss: 0.0411\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6034 - pi_loss: 0.5621 - v_loss: 0.0414\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6063 - pi_loss: 0.5651 - v_loss: 0.0412\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6053 - pi_loss: 0.5643 - v_loss: 0.0410\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.6052 - pi_loss: 0.5642 - v_loss: 0.0411 0s - loss: 0.6055 - pi_loss: 0.5644 - v_loss: \n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6050 - pi_loss: 0.5640 - v_loss: 0.0410\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6073 - pi_loss: 0.5662 - v_loss: 0.0411\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.6015 - pi_loss: 0.5604 - v_loss: 0.0411\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6031 - pi_loss: 0.5619 - v_loss: 0.0412\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5988 - pi_loss: 0.5578 - v_loss: 0.0410\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.6003 - pi_loss: 0.5594 - v_loss: 0.0408\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5961 - pi_loss: 0.5551 - v_loss: 0.0410\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.6000 - pi_loss: 0.5590 - v_loss: 0.0410\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5925 - pi_loss: 0.5515 - v_loss: 0.0410\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5963 - pi_loss: 0.5551 - v_loss: 0.0412\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5970 - pi_loss: 0.5562 - v_loss: 0.0408\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5926 - pi_loss: 0.5516 - v_loss: 0.0410\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5971 - pi_loss: 0.5559 - v_loss: 0.0413\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5953 - pi_loss: 0.5545 - v_loss: 0.0408\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5916 - pi_loss: 0.5508 - v_loss: 0.0409\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5909 - pi_loss: 0.5500 - v_loss: 0.0409\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5892 - pi_loss: 0.5483 - v_loss: 0.0409\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5896 - pi_loss: 0.5489 - v_loss: 0.0407\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5892 - pi_loss: 0.5482 - v_loss: 0.0409\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5905 - pi_loss: 0.5496 - v_loss: 0.0409\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5852 - pi_loss: 0.5447 - v_loss: 0.0405\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5855 - pi_loss: 0.5448 - v_loss: 0.0408\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5832 - pi_loss: 0.5425 - v_loss: 0.0407\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5828 - pi_loss: 0.5420 - v_loss: 0.0408\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 60s 998us/step - loss: 0.5844 - pi_loss: 0.5434 - v_loss: 0.0410\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5811 - pi_loss: 0.5404 - v_loss: 0.0406\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5834 - pi_loss: 0.5427 - v_loss: 0.0407\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.5820 - pi_loss: 0.5414 - v_loss: 0.0406\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5780 - pi_loss: 0.5370 - v_loss: 0.0410 0s - loss: 0.5780 - pi_loss: 0.5371 - v_loss: 0.\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5768 - pi_loss: 0.5363 - v_loss: 0.0405\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5761 - pi_loss: 0.5354 - v_loss: 0.0407\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5797 - pi_loss: 0.5394 - v_loss: 0.0404\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5745 - pi_loss: 0.5341 - v_loss: 0.0404\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5775 - pi_loss: 0.5373 - v_loss: 0.0402\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5744 - pi_loss: 0.5336 - v_loss: 0.0408\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5781 - pi_loss: 0.5375 - v_loss: 0.0407\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5758 - pi_loss: 0.5353 - v_loss: 0.0405\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5745 - pi_loss: 0.5339 - v_loss: 0.0406\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5749 - pi_loss: 0.5343 - v_loss: 0.0406\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5711 - pi_loss: 0.5309 - v_loss: 0.0401\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5700 - pi_loss: 0.5294 - v_loss: 0.0406\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.5699 - pi_loss: 0.5296 - v_loss: 0.0404\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5701 - pi_loss: 0.5296 - v_loss: 0.0405\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5722 - pi_loss: 0.5318 - v_loss: 0.0404\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5624 - pi_loss: 0.5220 - v_loss: 0.0405\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.5708 - pi_loss: 0.5306 - v_loss: 0.0403\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5637 - pi_loss: 0.5237 - v_loss: 0.0401\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5653 - pi_loss: 0.5251 - v_loss: 0.0403\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5674 - pi_loss: 0.5269 - v_loss: 0.0405\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.5644 - pi_loss: 0.5241 - v_loss: 0.0403\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5617 - pi_loss: 0.5215 - v_loss: 0.0402\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.5599 - pi_loss: 0.5196 - v_loss: 0.0403\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 59s 978us/step - loss: 0.5626 - pi_loss: 0.5228 - v_loss: 0.0398\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 59s 976us/step - loss: 0.5629 - pi_loss: 0.5231 - v_loss: 0.0397\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 58s 973us/step - loss: 0.5618 - pi_loss: 0.5218 - v_loss: 0.0399\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 58s 970us/step - loss: 0.5599 - pi_loss: 0.5200 - v_loss: 0.0400\n"
     ]
    }
   ],
   "source": [
    "rnn = RecurrentNN(args)\n",
    "# cnn = ConvolutionalNN(args)\n",
    "rnn.train(dataset)\n",
    "# cnn.train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dictionary of MCTSs and a Game, returns a dictionary of each models best results over number of simulations\n",
    "def evaluation_run(game, MCTSs):\n",
    "    results = {}\n",
    "    optimal_val, optimal_path = game.optimal_sol()\n",
    "    for model in MCTSs.keys():\n",
    "        state = [game.getStartState()]\n",
    "        mcts_reward = 0\n",
    "        mcts_actions = []\n",
    "        \n",
    "        while not game.getGameEnded(state[-1]):\n",
    "            action = np.argmax(MCTSs[model].getActionProb(state))\n",
    "            next_state, reward = game.getNextState(state[-1], action)\n",
    "            state+=[next_state]\n",
    "            mcts_actions += [action]\n",
    "            mcts_reward += reward\n",
    "        results[model] = copy.deepcopy((MCTSs[model].val, MCTSs[model].num_sim))\n",
    "    return results, optimal_val   \n",
    "\n",
    "# Given MCTS results and optimal solution returns a pandas series of the commulative number of games where a solution\n",
    "# within a threshold of the optimal was found per number of simulations\n",
    "def add_entry(model_results, optimal, args):\n",
    "    count_v = np.zeros(args['numMCTSSims']+1)\n",
    "    for i,j in enumerate(model_results[1]): count_v[j] = model_results[0][i]\n",
    "    return ((pd.Series(count_v).replace(to_replace=0, method='ffill')/optimal)<1.1)*1\n",
    "\n",
    "# Given games and neural nets, runs models on games and computes the number of games which a solution was found\n",
    "# within a threshold of the optimal\n",
    "#\n",
    "# games - a list of games to test on the models\n",
    "# nets - a dictionaryu of the neural nets to be tested, None for no net\n",
    "# args - argument dictionary\n",
    "def create_comparison(games, nets, args):\n",
    "    totals = {nn:pd.Series(np.zeros(args['numMCTSSims']+1)) for nn in nets.keys()}\n",
    "    for i,game in enumerate(games):\n",
    "        print(i, end='...')\n",
    "        mcts_dic = {nn:MCTS(game, nets[nn], args) for nn in nets.keys()}\n",
    "        results, optimal = evaluation_run(game, mcts_dic)\n",
    "        for model in totals.keys():\n",
    "            totals[model] += (add_entry(results[model], optimal, args))\n",
    "    for model in totals.keys():\n",
    "        totals[model]/=len(games)\n",
    "    print()\n",
    "    return totals\n",
    "\n",
    "# Prints results from create_comparison\n",
    "def plot_comparison(res):\n",
    "    for model in res.keys():\n",
    "        plt.plot(list(range(len(res[model]))), res[model])\n",
    "    plt.xlabel(\"Number of Simulations\")\n",
    "    plt.ylabel(\"Percentage of Games within Threshold\")\n",
    "    plt.legend(res.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21...22...23...24...25...26...27...28...29...30...31...32...33...34...35...36...37...38...39...40...41...42...43...44...45...46...47...48...49...50...51...52...53...54...55...56...57...58...59...60...61...62...63...64...65...66...67...68...69...70...71...72...73...74...75...76...77...78...79...80...81...82...83...84...85...86...87...88...89...90...91...92...93...94...95...96...97...98...99...\n",
      "CPU times: user 9min 19s, sys: 34.3 s, total: 9min 53s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "args['numMCTSSims']=1000\n",
    "\n",
    "game_list = [TSPGame(args) for i in range(100)]\n",
    "\n",
    "nets = {\"No NN\": None, \n",
    "          \"LSTM\": rnn}\n",
    "\n",
    "res = create_comparison(game_list, nets, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNXZwPHfkxASkrCGsIaYCCgom4CouFYUl9dKa8GtrvgW34rFpWrV9u3i28WtdavW4l5rxbq0RWq1akWLCwJCBQQUWcOehSUTsj/vH/cmDiGZuZnMnSV5vp9PPjP33jNnnpuBPHPPueccUVWMMcYYgJR4B2CMMSZxWFIwxhjTyJKCMcaYRpYUjDHGNLKkYIwxppElBWOMMY0sKRhjjGlkScEYY0wjSwrGGGMadYp3AK3Vu3dvLSgoiHcYxhiTVJYsWVKsqrnhyiVdUigoKGDx4sXxDsMYY5KKiGz0Us6aj4wxxjSypGCMMaaRJQVjjDGNkq5PoTk1NTUUFRVRWVkZ71DiLiMjg7y8PNLS0uIdijEmCbWLpFBUVETXrl0pKChAROIdTtyoKiUlJRQVFVFYWBjvcIwxSahdNB9VVlaSk5PToRMCgIiQk5NjV0zGmIi1i6QAdPiE0MB+D8aYtmgXzUfGGJNMKmvqeOr9Deyvrm3V6yYN78voQT18isphSSFKRIQbb7yRX//61wDce++9lJeX89Of/tTT659++mmmT5/OsmXLGDVqFAAjRoxg3rx5FBQUUFBQwLhx43j55ZcBeOmll5g3bx5PP/20H6djjPHRh+tKuOv11QC05uK+T7cMSwrJIj09nVdeeYXbbruN3r17R1RHXl4ev/jFL3jhhReaPb548WJWrlzJkUce2ZZQjTFxVryvCoB/3/I1BvXKjHM0B2o3fQrx1qlTJ2bMmMF999130LGNGzcyadIkRo0axaRJk9i0aVOzdZxzzjmsXLmSNWvWNHv8pptu4pe//GVU4zbGxF5poBqAnlmd4xzJwdrdlcLPXl3JZ1v3RrXOIwZ04ydfD//tfObMmYwaNYpbbrnlgP3XXnstl112GZdffjlPPvkks2bN4q9//etBr09JSeGWW27hl7/8Jc8888xBx88//3weeeQR1q5dG/nJGGPiZs7Hm3hh8Wa27a6kc6cUsjqnxjukg7R4pSAiy0Xk05Z+YhlksujWrRuXXXYZDz744AH7P/zwQy6++GIALr30UhYsWNBiHRdffDEfffQR69evP+hYamoqN998M7/61a+iG7gxJib+snQL64sDDO2bzYwTD03IuwVDXSmc4z7OdB+fdR+/DVT4FlEbeflG76frr7+esWPHcuWVV7ZYJtQ/hE6dOvH973+fu+66q9njl156Kb/61a+sX8GYJFQaqObYwhwevXRcvENpUYtXCqq6UVU3Aser6i2qutz9uRU4I3YhJpdevXpx/vnn88QTTzTumzhxInPmzAHgueee44QTTghZxxVXXMFbb73Frl27DjqWlpbGDTfcwP333x/dwI0xbVJdW0+gqjbkT0mgml7ZidePEMxLn0KWiJygqgsARGQikOVvWMnt+9//Pr/97W8btx988EGmT5/OPffcQ25uLk899VTI13fu3JlZs2Zx3XXXNXv8qquu4uc//3lUYzbGRK4sUM2Jd79DeVX4cQe9s9NjEFHkRFVDFxAZBzwJdHd37Qamq+onYSsXORN4AEgFHlfVO5scvwK4B9ji7vqtqj4eqs7x48dr00V2Vq1axfDhw8OF02HY78OY2Fq2eTffePh9Lhg/iMF9Wv7OnCLCuWMG0KdrRgyjc4jIElUdH65c2CsFVV0CjBaRbjhJZI/HAFKBh4HTgSJgkYjMVdXPmhR9QVWv9VKnMcYkojL3FtMLJgxibH7POEfTNi0mBRG5sYX9AKjqb8LUPQFYq6rr3NfNAaYATZOCMcYkjdJANR+vLz1g38L1JQDkJOC4g9YKdaXQtY11DwQ2B20XAcc0U+5bInIS8Dlwg6publpARGYAMwDy8/PbGJYxxkTunjfW8PzHBw9ATe+UQm7XxO4v8KLFpKCqP2tj3c3dd9m0A+NV4HlVrRKR/wGeAU5tJpbZwGxw+hTaGJcxxkRs2579DO2TzQMXHnXA/pzszmR2Tv7xwGHPQETygIeA43H+qC8ArlPVojAvLQIGBW3nAVuDC6hqSdDmY0DzN+cbY0yCKA1U079HF44Y0C3eofjCS1p7CvgTMM3dvsTdd3qY1y0ChopIIc7dRRcCFwcXEJH+qrrN3TwXWOUxbmOM8d26XeU888EG6oLu0lxfHOC04dlxjMpfXibEy1XVp1S11v15GsgN9yJVrQWuBd7A+WP/Z1VdKSJ3iMi5brFZIrJSRP4DzAKuiOgsEkB29sH/SNasWcMpp5zCmDFjGD58ODNmzOCNN95gzJgxjBkzhuzsbA4//HDGjBnDZZddxvz58xGRAwa+LV26FBHh3nvvjeXpGGOAVz7ZwjMfbuQfy7c3/qR3SuG4wTnxDs03Xq4UikXkEuB5d/sioCRE+Uaq+hrwWpN9Pw56fhtwm7dQk8+sWbO44YYbmDJlCgDLly9n5MiRnHGGMyD8lFNO4d5772X8eOfW4fnz5zNy5EheeOEFrrrqKgDmzJnD6NGj43MCxnRwJYEqemens/hHp8U7lJjxcqUwHTgf2A5sA6a6+0wY27ZtIy8vr3F75MiRYV+Tn59PZWUlO3bsQFV5/fXXOeuss/wM0xjTgpLy6nZxm2lreBm8tgmnvT85/ONW2L48unX2Gwln3Rm+XBM33HADp556KhMnTmTy5MlceeWV9OgRftWkqVOn8uKLL3LUUUcxduxY0tOT/zY3Y5LNY++t45+f7eC4Q+PYVFS+E/74Laja52x/7Ycwalro17RR2CsFEckVkdtFZLaIPNnw42tU7cSVV17JqlWrmDZtGvPnz+fYY4+lqqoq7OvOP/98XnzxRZ5//nkuuuiiGERqjGnqn59tB+CqEwrjF8S2T2H7p5AzGPKOhuyw3blt5qVP4W/Av4G3gDp/w4mCCL7R+2nAgAFMnz6d6dOnM2LECFasWMG4caGnze3Xrx9paWm8+eabPPDAA3zwwQcxitYY06A0UM3ZI/tx2hF94xdERbHzeOZd0HtITN7SS1LIVNUf+B5JO/T6668zadIk0tLS2L59OyUlJQwcONDTa++44w527txJamrircxkTLxU1daxc2/4q+1oKAlU0yve/Ql73OFgWbFrwvKSFOaJyNnunUSmBRUVFQd0Kt94440UFRVx3XXXkZHhzIh4zz330K9fP0/1TZw40Zc4jUlm3/nDEt77/OB1RvzSNw6zmR7go985jxnh+yKjpcWps0VkH84IZsFZP6EKqHG3VVXjMpzPps4Oz34fpr064a5/0b97Bhcc7f8caKkpcOqwvnTvkub7e7Xo7sHQqxD++602V9XmqbNVta0T4hljTFSVBqo548h+TB2XF75wsquvh/1lUHhFTN/Wy9xHxwPLVDXgDmIbC9zv3qpqjDER21RSwYK1xZ7K1qlSUV0X/3b+WKjZD/95HrQOsnrH9K299Cn8DmeRndHALcATwLPAyX4G1lqq2rjWQ0cWbiU9YxLJXa+v5u/Lt4UvGGRwbvudd6jRqldh3g3O895DY/rWXpJCraqqiEwBHlDVJ0Tkcr8Da42MjAxKSkrIycnp0IlBVSkpKWns2DYm0e3cV8m4Q3ryyLfHeirfKUXISfA1jqNinzNGguuXQ4/YriHjJSnsE5HbgEuBE91lNuPY83KwvLw8ioqK2LUrdnclJKqMjIwD7oIyJpGVBKoZ3q8bfbvZF5kDVBRDamfoPih82SjzkhQuwJnyerqqbheRfOAef8NqnbS0NAoL4zjq0Bjj2T1vrGZ9cQCAorL9HD84tm3mzdr4ISx8lIPXAYuTrcsgszfEoeXDy9xH20XkZaChYasY+IuvURlj2qXyqloefudLemen0zMzjcKcLE453P+pG8Ja9kdY/XdnOolEkNYFjojPlHNe7j76Ds76yL2AwThrLz8KTPI3NGNMe1NaXg3AD848nGnjY9800qJACeQOg+8uiHckcedl6uyZOEtx7gVQ1S+APn4GZYxpn0oCzhQVOdkJdltpRXFMp5JIZF76FKpUtbrhrh4R6UTCNLwZYxLJjS8s481VO1o8Xlvn/OnoldXKO4jq6+HxSVDyZVvCa1nVXhjxLX/qTjJeksK7InI70EVETgeuAV71NyxjTDL699piBvboEnK5ym4ZaYxo7aL3lbth6ydQcCL0HdHGKFsw+gJ/6k0yXpLCrcBVwHLgapzlNR/3MyhjTPJRVcoC1Uwdl8cPzhwW3cor3BWAx14Go86Pbt3mACGTgjsm4RlVvQR4LDYhGWOS0d7KWmrr1fvylaqwazVUV4Qvu3Ol85hp7f5+C5kUVLXOXXmts6pWxyooY0zyKQ04fyI8z020+WN4cnLr3qS7Dcz0m5fmow3A+yIyFwg07FTV3/gVlDEm+ZS6dxZ5Tgq7NzqPX38QuvYPXz6jO+QeHmF0xisvSWGr+5MC2HTaxphmlbhjEHK83lkUcGdHHf51yOzlU1SmtbyMaP5ZLAIxxiSnjSUB5n26jRVb9gDQq+kYhM/mQvGag1+4/j2Q1JiuKmbC8zKi+TDgJqAguLyqnupfWMaYZDH7vXU8t9BZXqVftwxyg2cxra+Hl6ZDfU3zLx44DlK8jKE1seKl+ehFnGktHgfq/A3HGJNsdu2r4rC+2fx91omkipCSEjSJW+VuJyFM/gUcc/XBL07x8ifIxJLX9RR+53skxpikVBqoJicrnbTUZr7xN4wvyO4LqQk1475pQYtJQUQaen5eFZFrcGZGrWo4rqqlPsdmjElwSzaWsXhjGf81Kujuod2bYd71UFMJ1fucfTavUNII1Zi3BFgMXA7cDHzg7mvYH5aInCkia0RkrYjcGqLcVBFRERnvPXRjTLz98zNnhbBzRw/4aufG92HtW1BbCZ27wmFnQv8xcYrQtFao5qOLVfXDSCt2R0M/DJwOFAGLRGSuqn7WpFxXYBawMNL3MsbER2l5Nf26ZXDGkf2+2tlwq+klL0MXu7Mo2YS6Uni4jXVPANaq6jp3NPQcYEoz5f4PuBuobOP7GWOirK5eqamrb/6npobd5RXkZqZAXc1XP4GdTgdyRvd4h28iEOpKoa3rwA0ENgdtFwHHHPAGIkcBg1R1nojc1Mb3M8ZE0X8272baox9SXVd/0LFR8iUvdv4Zj0mts+P/mhTo2j8uS0matguVFArdqS2aparh1opr7l9E4zoMIpIC3AdcEaYeRGQGzupv5OfnhytujImCNdv3UV1Xz9UnH0rX9AP/VAzfvor0z2tZkncZef360rdbk1HMA46KYaQmmkIlhV3Ar9tQdxEQvN5eHs50GQ26AiOA+e4CPv2AuSJyrqoe0JGtqrOB2QDjx4+3BX6MiYFidy6j6yYNJbNzkz8VC1Lhcxh32Z3QOSsO0Rm/hEoK+1T13TbUvQgYKiKFwBbgQuDihoOqugfo3bAtIvOBm5omBGNM7JQGqvnP5t0ALC/aQ0ZaysEJoaoclr8MqemWENqhUElhQ1sqVtVaEbkWeANIBZ5U1ZUicgewWFVbbJoyxsTHHa+u5K/LvrqgH9on++BC798PO5Y7C92bdqfFpKCq57W1clV9DWeltuB9P26h7CltfT9jTNts3VPJiIHd+Pk3RgKQ17PLwYX2bHEeL58Xw8hMrNjEI8aYRqWBaob2yWbMoBDjCyqKod8oyM6NXWAmZiwpGGP41+od/PuLYrbu3s8xhWHWNggUQ1bv0GVM0vKUFERkIHAIB06d/Z5fQRljYuuuf6zhy13lZKV34uiCMEmhogRyhsQmMBNzXtZTuAu4APiMr6bOVsCSgjHtREmgmmnj8/jVeaPCF64osSuFdszLlcI3gMNVtSpsSWNM0qmvV8oqqr2trVxTCdXlkGmznrZXXpLCOiCNoGmzjTGJp6q2julPL2Ln3tb9V61Xpa5e6RVubeXFT8GH7pRodqXQbnlJChXAMhF5mwPXU5jlW1TGmFYrKtvP+2tLGDOoBwN6ZLTqtSMGdue04X1CF1r1qtN0NPJ8GHJaGyI1icxLUpjr/hhjElhpoBqAG08/jJMO8+F20YpiZ03lbz0W/bpNwgibFFT1mVgEYoxpmy1l+wG89Q14VR2Ayr3O8/Jd0OeI6NVtElKo5Tj/rKrni8hygmY3baCqHm5TMMbEQm1dPde/sAyAPl3D9A14VV8H949yrhAaZPeNTt0mYYW6UrjOfTwnFoEYYyJXVlEDwNcOz6VPt9b1J7SootRJCCOnwSHHg6TA4WdHp26TsELNfbTNfdwYu3CMMZEoq3D6E84bmxe9ShuuEA4/C0Z8K3r1moTmZfDaecBdQB+chXMEUFXt5nNsxnRoK7bsYfX2fZ7Kri8uByDHa39C1T5Y8w+or225TMla5zHTbj/tSLzcfXQ38HVVXeV3MMaYr1z97BK27N7vuXyKQH5OprfCn/wB3rg9fDlJgZ4FnmMwyc9LUthhCcGY2FJVdu6r5JJj87n6pMGeXpOV3sn7nUf7tkGnDJi5MHS5zl0hy0YvdySh7j5qWE9hsYi8APyVAwevveJzbMZ0WHsra6mpUwpyshjUy+O3/9YIlDjNQnYVYJoIdaXw9aDnFcDkoG0FLCkY45OGgWg9M6Mw5qB8F/zrDmfeogYb37epKkyzQt19dCWAiByvqu8HHxOR4/0OzJiOrDTgXJT3yo5CUlg33+lD6D4IUtz/8qmdYZjdbW4O5qVP4SFgrId9xpgoKSl3rhQ8300USmCX83j1e5AZZq0E0+GF6lM4DpgI5IrIjUGHugGpfgdmTEfW0HwUlSkrKopBUiEjxBKbxrhCXSl0BrLdMl2D9u8FpvoZlDEdzb7KGr75yAeUuclgf42znlVOuOmsw/nbTFj+krP+QUpKW8M0HUCoPoV3gXdF5Gkb1WyMv9YXB1i7s5xTh/VpnPa6sHc2XTq38aL8i7egZyGccEMUojQdQajmo/tV9XrgtyLS3IR45/oamTEdSIl7hTDza0MYd0jP6FSq6qx/MOYiGH1BdOo07V6o5qNn3cd7YxGIMR3R7opqtu6u5LOtzvTUUelYBichbPsP1NfYNBWmVUI1Hy1xn6YCH6lqRWxCMqbjOP/3H/L5DmfeotQUoXe0pr1e8xrMudh53q1/dOo0HYKXW1KvAB4VkRLg3+7PAlUt8zMwY9o7VWVjSQVnHNmXbx6VR7/uGWSne/kv6UHZBufx/D/YdNemVbysvHYZgIgMwLnr6GFggJfXGmNaVlFdR1VtPUfl9+TMEf2iW3mg2BmoNvxcEIlu3aZd8zJ19iXAicBIoBj4Lc7VgjEmSHlVLS8t3kx1Xb2n8nv3O9NWt3oswuZFsOnD0GU2LHBuQ7WEYFrJy7f9+4EvgUeBd1R1g9fKReRM4AGcfonHVfXOJsf/B5gJ1AHlwAxV/cxr/cYkkn8s38ZPX23dP99OKcJhfbuGLxjs7zfA9uXhyw05rXX1GoO35qPeInIkcBLwCxEZCqxR1UtDvU5EUnGamk4HioBFIjK3yR/9P6nqo275c4HfAGdGdirGxNeucme+osU/Oo0uad7GF6SmCBkeyzYq3wmjL4az7wldLs2H2VVNu+el+agbkA8cAhQA3QEv18cTgLWqus6tZw4wBWhMCqq6N6h8Fs7sq8YkpdLyajLSUuidHaU7iJrTMPaga19Iz/bvfUyH5aX5aEHQz29Vtchj3QOBzUHbRcAxTQuJyEzgRpxpNU71WLcxCeEvS4t45ZMtAHyxo7xt01J88BB8+a/QZerrnCU0beyB8YmX5qNREdbdXA9XcyOjHwYeFpGLgR8Blx9UkcgMYAZAfn5+hOEYE33Pf7yZVVv3MqRvNv17ZHDKYX0ir+yjR6GuKvzCN4ccD4eeEvn7GBOCn7eVFgGDgrbzgK0hys8BftfcAVWdDcwGGD9+vDUxmYRRGqjmhKG9+d0l49pWkaozm+mE78Dkn0cnOGMi4Oe0iYuAoSJSKCKdgQuBucEF3E7rBv8FfOFjPMZEXWmgOjrTW1cHoLbSmoVM3Pl2paCqtSJyLfAGzi2pT6rqShG5A1isqnOBa0XkNKAGKKOZpiNjEsH1c5by12XNX+jmtLZjub4OHp4AJWsPPpaVG0F0xkSPl7uP7gZ+DuwHXgdGA9er6h/DvVZVXwNea7Lvx0HPr2ttwMbEwyebdjOsX1cmH3ngyONUEc4/Oq91le0vcxLC0Mkw4KigyjrDsP+KQrTGRM7LlcJkVb1FRL6J008wDXgHCJsUjGkvSgPVTBqex42nH9b2ygLFzuOoC2CkrVdlEouXpJDmPp4NPK+qpWJD500HsGLLHnZX1FCnSnlVbfSmtd6y2HnMzIlOfcZEkZek8KqIrMZpPrpGRHKBSn/DMia+isoqOOehBQfsG9izS3Qqf9VtNe1ht1ebxONlnMKtInIXsFdV60SkAmdksjHt1rY9zvee/z3nCEbldSctNYWRA7u3veK6Gmfw2ZHfhJzBba/PmCjz0tGciTNpXT7OALIBwOHAPH9DMyZ+Ssqd5TGPKezFiGgkgwYVJc5jwQnRq9OYKPLSfPQUsASY6G4XAS9iScEkkb2VNTzx7/VU1tZ5Kr9m+z4AcrKj1I/QYNlzzqONRzAJyktSGKyqF4jIRQCqul+sp9kkmflrdvHA21/QOTXF8xIDg3Ozoj+53eKnnMe+I6JbrzFR4iUpVItIF9x5i0RkMFDla1TGRFmJO631R7dPis4I5EjtL4NjZ0LvIfGLwZgQvCSFn+AMWhskIs8Bx+Os22xM0igNVJMi0KNLWvjCfqmphOpyyLJbUU3i8nL30Zsi8glwLM7Mp9eparHvkRnTghVb9vDDv66g1uOylwDb91TSM7MzKSk+tXy+fjtsCLNKbb3bn2HjE0wC8zr30UCc+Ys6ASeJCKr6in9hGdOyBWuL+c/m3Zw6rA9e/8b3757BhMJe/gW19I+Q2RNyh4cu13sIDLZlQ0zi8nJL6pPAKGAlX624poAlBRMXZYFqOndK4YnLx5MQ9zzU1UDVHjhuJpzyg3hHY0ybeLlSOFZVj/A9EmOC1Ncre/bXNHts+95KcrI6J0ZCqK+H0nXOc+srMO2Al6TwoYgcoaqfhS9qTHTc+sqn/Hlxyyu/jsqL4oCytnh1Fix91nme3Te+sRgTBV6SwjM4iWE7zq2oAmgbluk0Jqw1O8oZ2iebbx/T/PxA4wt87B9ojZ2fQe4wOPYaGHJ6vKMxps28JIUngUuB5XzVp2CMr0oDVYzL78kVxxfGO5TQAsUwaAKMs/WhTPvgJSlscldJM8aTQFUt89fsorY+8u8Qxfuq6ZUV5dHEzfnyX1BRGvnrA7tsygrTrnhJCqtF5E/AqwSNZLZbUk1Lnv94Ez//+6o211PQOzMK0YRQug6e/Wbb6+l1aNvrMCZBeEkKXXCSweSgfXZLqmnRjr2VZKSl8PdZJ0ZcR6oIh+T4nBT2bnMepzziNAFFQlIsKZh2xcuI5itjEYhpP0oC1eRkpTM4NzveoYRW4Q7M7zcSeg+NbyzGJAgvg9cygKuAI4GMhv2qOt3HuEyS+WLHPp5YsJ66emXhutL4TjrX1H/mwPpmpqAo/dJ5zLI+AWMaeGk+ehZYDZwB3AF8G2h7g7FpV15ZuoU5izYzoLvzveHUYX3iHFGQd++CfduhSzO3seZPhKwEitWYOPOSFIao6jQRmaKqz7idzm/4HZhJLiXlVfTtls4Ht02KdygHq66AkdPg3AfjHYkxCS/FQ5mGuQZ2i8gIoDtQ4FtEJimVBmJ0C2kkaiogzedOa2PaCS9XCrNFpCfwv8BcINt9bgzPLdzIb/+1lpLyao4u7BnvcJpXUwGdLSkY44WXu48ed5++C9i9d+YA767Zxf6aOr5x1ADOGTUg3uEcrLYa6mshrUu8IzEmKbSYFEQkDyhQ1QXu9o04VwkAf1LVtTGIzyS40kA1w/t14+6po+MdSvNqKpzHtKz4xmFMkgjVp3AP0CNo+2oggDNw7Wd+BmUSm6qyubSCtTvL2bmvil7ZCXT7aVONScGuFIzxIlTz0eGqOi9ou0JVfw0gImHWHTTt2VurdvKdPyxu3D79iASeMrraTQqd7UrBGC9CJYWMJtvB9xp6Wk1ERM4EHsBZyvNxVb2zyfEbgf8GaoFdwHRV3eilbhM/G0sCANwzdRQZaamcMCSBB39VlDiPzY1RMMYcJFRS2Ccih6nq5wCqWgogIsOA8nAVi0gq8DBwOlAELBKRuU0W61kKjFfVChH5LnA3cEFkp2JipSRQTVqqMHVcXmKsfhZKw1QWtiqaMZ6ESgo/AeaJyC+AT9x944Dbges81D0BWKuq6wBEZA4wBWhMCqr6TlD5j4BLvIdu4mHhuhIWrS+lZ2aCLIfZnJV/gfKdzvMit5nLprc2xpMWk4Kqvi4i5wG3ALPc3SuA81R1hYe6BwKbg7aLgGNClL8K+EdzB0RkBjADID+/+ZW4TGzMmrOUHXurOHFogv6R3bMFXrziwH2ZOZBtU1kY40XIcQruH//LIqy7ua+R2mxBkUuA8cDJLcQxG5gNMH78+GbrMP6rr1eKy6u56oRCbjtrWLzDaV75dufxvMdgyGnO87RM6JSgo62NSTBeRjRHqggYFLSdB2xtWkhETgN+CJysqlVNj5vEsbeyhrp6ZUCPLnRK9TJDShw0rKLWswAyrXPZmNbyMyksAoaKSCGwBbgQuDi4gIgcBfweOFNVd/oYi2mlu19fzZrt+w7Yt7+mDoCceE6L/cVbsOixlo/vcxfOybSOZWMiEWpE812q+gMRmaaqL7a2YlWtFZFrcWZUTQWeVNWVInIHsNhd9/kenFHSL7qdlptU9dyIzsRETU1dPY/M/5K+3dLJ7Xpgs8v4Q3oy7pA4znG09A+wbj7kHt5ymaFnQA/rezImEqGuFM4WkR8BtwGtTgoAqvoa8FqTfT8Oen5aJPUaf5UFqgH43qlDueTYQ+IcTROBEhgwFqY3e0+CMaaNQiWF14FiIEtE9uJ0HGvDo6p2i0F/Q4PJAAAXNUlEQVR8Jg5K3KSQUKunNagotqUzjfFRqFtSbwZuFpG/qeqUGMZkYmzmc5/w5qodjduqzg1eces7ePoc2Pxx88fqquCQibGNx5gOxMvU2VNEpC9wtLtroaru8jcsE0sL15cwtE82Jw7NbdzXNaMTR+XHoe+gvh42fgB5R0P+sQcfF4HRFx+83xgTFWGTgohMA+4F5uM0HT0kIjer6ks+x2ZioL5eKauo4YKjB3HzGQkw9qByN2gdHPkNOPa78Y7GmA7Hyy2pPwKObrhlVERygbcASwoJ5vMd+9hdURO+YJBAdS119Rr9pTRrKmHbMtD61r1uzxbn0aalMCYuvCSFlCZjCErwtraziaEtu/cz+b73In79wB5RXm9gwX3w7p3hy7Wkx6DwZYwxUeclKbwuIm8Az7vbF9DkNlMTf1vK9gNw21nDGDGwe6tem94pJfr9B7s3QVYf+FaIgWYtScuCvPHRjccY44mXjuab3YnxTsDpU5itqn/xPTLTKqXubaTHD+nd6qTgi4pi6NYfDj0l3pEYY1rB0zQXqvoK8IrPsZhWWLqpjHdWf9Wq99m2vQDk+L00ZvEXsPxF0DDzEu5YCbkJ0HFtjGkVP+c+Mj66959reH9tCcFLGuT3yqR3ts+zgX7wEHzyDM1PgtvE2Egn2DXGxIslhSRVvK+ayUf0ZfZlMW57D+yCviPgu+/H9n2NMTHh6S4iEekiIiFmIDOxVhKo9r+pqDmBYpuB1Jh2zMvgta/jDF7rDBSKyBjgDpvN1B9LN5Xxy9dWUVsfus2+JFDlz9xEG96Ht+9wBpA1Z/sKGHZ29N/XGJMQvDQf/RRnveX5AKq6TEQKfIuog3tnzS4WbSgLu9zlyYflcsaR/aIfwOf/gKJFcGizi+DBIcfBqAuj/77GmITgJSnUquqehF2kvZ0pDVTRIzONZ68KtZy1jwIl0LU/XGp3HRvTEXlJCitE5GIgVUSGArOAD/wNq+OpqK6lXmHXPp+aherroKYifLny7ZBlfQbGdFReksL3cNZQrsIZ1fwG8H9+BtXRvLBoEz94eXnj9jGFPqwt/Mdvwbp3vJUdOjn672+MSQpeRjRX4CSFH/ofTse0ats+uqSlcuPphwFw3GAfvqlv/xQGHQvDzwlfdvCk6L+/MSYpeLn76FWcFdeC7QEWA79X1Uo/AutISgPV9O2WzndOOtSfN6ivg/1lUHgiTPyeP+9hjGkXvDQfrQNyOXBCvB3AYcBjwKX+hJb8PlpXwu6K6rDl1u4sb30/Qk2l0xxU52Gq7JoKZwprm47aGBOGl6RwlKqeFLT9qoi8p6onichKvwJLdhtLAlw4+yPP5aeMGdC6N/h0Drx6Xete07OgdeWNMR2Ol6SQKyL5qroJQETygYavnOG/BndQ2/Y4rWp3njeS0YN6hC1f2DurdW+wdysgcPV7IB4GpnfKgJzBrXsPY0yH4yUpfB9YICJf4syCVghcIyJZwDN+BpfMGqayHpXXg+H9u0X/DQLF0KUn9B8V/bqNMR2Wl7uPXnPHJwzDSQqrgzqX7/czuGTz5a5ynvlgA3X1ytqd5UAUprIu/gIW/v7gaSfWzYcs6yMwxkSX11lShwKHAxnAKBFBVf/gX1jJ6aUlRfzhw430dhPBmEE9yGnrQLRlz8GixyAr9+BjI6e1rW5jjGnCyy2pPwFOAY7AWYbzLGABYEmhiZLyKvp2S2fh7adFr9LALsjuBzetiV6dxhjTAi9TZ08FJgHbVfVKYDTg80ouyamkvJpeWVH+1QRKmr9KMMYYH3hpPtqvqvUiUisi3YCdgE+jrJJLeVUt3358YeNYhO17Kjm6oJVTVGxeBH+7puXxBvu2Qf6xbYzUGGO88ZIUFotID5yBakuAcuBjL5WLyJnAA0Aq8Liq3tnk+Ek4ndWjgAtV9aVWxB53X+4s5z+bd3PcoTn07ZYOg2DKmIGtq2TDv6H4cxgxteVbS63vwBgTI17uPrrGffqoiLwOdFPVT8O9TkRSgYeB04EiYJGIzFXVz4KKbQKuAG5qbeCJoOG205vPPJyx+T0jq6SiBDp1galPRDEyY4yJjJeO5rdVdRKAqm5oui+ECcBaVV3nvmYOMAVoTApB9dVHEnwsVNfWs2Nv89M7Nd522to7jPZug7oq5/nuTXZrqTEmYbSYFEQkA8gEeotIT5wxCgDdAC9zMgwENgdtFwFxWjkmcjP/9AlvfrajxeMpAjnZrehcXvM6PH/Bgfvyjo4wOmOMia5QVwpXA9fjJIAlfJUU9uI0C4XT3FJtoRcebqkikRnADID8/PxIqojYul3ljB7Ug0uPPaTZ4wN6ZJCd7nW4B1Cy1nk85z5n6gmAgePaGKUxxkRHi3/NVPUB4AER+Z6qPhRB3UXAoKDtPGBrBPWgqrOB2QDjx4+PKLFEqjRQzXGDc5g6Li86FVYUQ0oajLsSbIlTY0yC8dLR/JCITAQKgst7GNG8CBgqIoXAFuBC4OLIQ42tJRvLWLVtL7v319ArM8JRyeU7Yc1rzrTVDTYthMwcSwjGmITkpaP5WWAwsAxomIBHCTOiWVVrReRanOU7U4EnVXWliNwBLFbVuSJyNPAXoCfwdRH5maoeGfnpRM/M5z5hu9vBPLhPdmSVfPAgfNDMRVbhSQfvM8aYBOClMXw8cISqtrrZRlVfw5kaI3jfj4OeL8JpVkoo9fXKrvIqrjy+gGu/NqR1HcnB9u2A7vnw328euL+LD2swG2NMFHhJCiuAfsA2n2NJGHsra6irV/J6ZkaeEMCdtygXuvaLXnDGGOMjL0mhN/CZiHwMVDXsVNVzfYsqzkrcQWkRzXD64cOwyV1xbetSGJR0d+EaYzowL0nhp34HkWgaRiq3et1kgHfvdqaryO4LXfvD8HOiHJ0xxvjHy91H74rIIcBQVX1LRDJxOo7brZLyCJNCXQ1U7oZTboNTbvUhMmOM8VfYqbNF5DvAS8Dv3V0Dgb/6GVS8NVwptHrVtIpS5zEzJ8oRGWNMbHhpPpqJM4/RQgBV/UJE+vgaVYz9a/UObvzzf6irc26wqqpzxhW06krhrZ/Bx7Od5zaXkTEmSXlJClWqWi3uYCsR6USE01UkqiUby9i7v4YrJhY27js0N4v0Tq1oJVv/HmT2gmOuhsGn+hClMcb4z0tSeFdEbge6iMjpwDXAq/6GFVulAWfFtB9//YjIK6kohrwJMOnH4csaY0yC8rIc563ALmA5ziR5rwE/8jOoWNq+p5INxRX0ykqLvJJ926FsgzUbGWOSnpcrhS44U1Q8Bo2L53QBKvwMLBZUlcn3vcveylpOPqwN6yDP/prz2K2Vq64ZY0yC8XKl8DZOEmjQBXjLn3Bia29lLXsra7lowiDumToqskrqamDfVjjkeJjwnegGaIwxMeYlKWSoannDhvs807+QYqfh1tOjC3rRp1tGZJVUlDiPI74FaV1ClzXGmATnpfkoICJjVfUTABEZB+z3Nyx/qSp/XryZT4v2ABGOXG4QKHYerT/BGNMOeEkK1wEvikjDAjn9gQtClE942/dW8oOXlwPQJS2VwbkRTo0Nzl1HAJmWFIwxyS9kUhCRFKAzMAw4HGeJzdWqWhOD2HxTXlkLwAMXjuGcUQNITWnDgjd2pWCMaUdCJgVVrReRX6vqcThTaLcL+2uctYKy0zu1LSHAV30KNrWFMaYd8NLR/E8R+ZZI+1k/sqLaSQpd0qIwr98n7gJ0XXq2vS5jjIkzL30KNwJZQJ2I7MdpQlJV7eZrZD5quFLI6ByFpBAohvRukNKuJ441xnQQXqbO7hqLQGKp0r1SyGxrUlB1mo+OuyYKURljTPx5mTpbROQSEflfd3uQiEzwPzT/7KtyOpojaj6qq4HaauenohTqa+zOI2NMu+Gl+egRoB44Ffg/oBx4GDjax7h88+DbX/CbNz8HICvdy+kH+fwNeP5C0PoD92e3q5nEjTEdmJe/iseo6lgRWQqgqmUi0obRXvH1+Y599MrqzO1nD6d3dnrrXrz9UychfO1H0NDv3ikDhv1X9AM1xpg48JIUatxJ8BRARHJxrhySUnVtPX26pjN1XF7rXxwogc5d4eSbox+YMcYkAC9J4UHgL0AfEfkFMJUknjq7c/VuJtZ/Cp9HMFPHzpWQZeMRjDHtl5e7j54TkSXAJJzbUb+hqqt8j8wn3yx7gkmB1+BPEVZQeHJU4zHGmETSYlIQkQzgf4AhOAvs/F5Va2MVmF+yavewPbU//aY/F1kFvQZHNyBjjEkgoa4UngFqgH8DZwHDgetjEZSfOtfvJ5DaHQaOi3coxhiTcEIlhSNUdSSAiDwBfBybkPyVVl9FbVor7zoyxpgOItTgtcaZUCNtNhKRM0VkjYisFZFbmzmeLiIvuMcXikhBJO/TGulaSXWqLYZjjDHNCZUURovIXvdnHzCq4bmI7A1XsXsb68M4TU9HABeJyBFNil0FlKnqEOA+4K7ITsO7zlpJXUqEq6wZY0w712JSUNVUVe3m/nRV1U5Bz71MhjcBWKuq61S1GpgDTGlSZgpO3wXAS8Akv2djzdAqajvZlYIxxjTHy9TZkRoIbA7aLnL3NVvGbaLaA/gyEGDRKw+w4Y4R9NZS6qz5yBhjmtXKyX9apblv/BpBGURkBjADID8/P6JgOmXnUJpZSCmH0v2Yb0dUhzHGtHd+JoUiYFDQdh6wtYUyRSLSCegOlDatSFVnA7MBxo8ff1DS8OKoyZfA5EsieakxxnQYfjYfLQKGikihO4HehcDcJmXmApe7z6cC/1LViP7oG2OMaTvfrhRUtVZErgXeAFKBJ1V1pYjcASxW1bnAE8CzIrIW5wrhQr/iMcYYE56fzUeo6mvAa032/TjoeSUwzc8YjDHGeOdn85ExxpgkY0nBGGNMI0sKxhhjGllSMMYY08iSgjHGmEaSbMMCRGQXsDHCl/cGiqMYTjKwc+4Y7Jw7hrac8yGqmhuuUNIlhbYQkcWqOj7eccSSnXPHYOfcMcTinK35yBhjTCNLCsYYYxp1tKQwO94BxIGdc8dg59wx+H7OHapPwRhjTGgd7UrBGGNMCB0mKYjImSKyRkTWisit8Y4nGkRkkIi8IyKrRGSliFzn7u8lIm+KyBfuY093v4jIg+7v4FMRGRvfM4iciKSKyFIRmeduF4rIQvecX3Cna0dE0t3tte7xgnjGHSkR6SEiL4nIavfzPq69f84icoP773qFiDwvIhnt7XMWkSdFZKeIrAja1+rPVUQud8t/ISKXN/deXnWIpCAiqcDDwFnAEcBFInJEfKOKilrg+6o6HDgWmOme163A26o6FHjb3Qbn/Ie6PzOA38U+5Ki5DlgVtH0XcJ97zmXAVe7+q4AyVR0C3OeWS0YPAK+r6jBgNM65t9vPWUQGArOA8ao6Amf6/Qtpf5/z08CZTfa16nMVkV7AT4BjgAnATxoSSURUtd3/AMcBbwRt3wbcFu+4fDjPvwGnA2uA/u6+/sAa9/nvgYuCyjeWS6YfnFX83gZOBebhLOtaDHRq+nnjrOdxnPu8k1tO4n0OrTzfbsD6pnG358+Zr9Zv7+V+bvOAM9rj5wwUACsi/VyBi4DfB+0/oFxrfzrElQJf/QNrUOTuazfcy+WjgIVAX1XdBuA+9nGLtZffw/3ALUC9u50D7FbVWnc7+Lwaz9k9vsctn0wOBXYBT7lNZo+LSBbt+HNW1S3AvcAmYBvO57aE9v05N2jt5xrVz7ujJAVpZl+7ue1KRLKBl4HrVXVvqKLN7Euq34OInAPsVNUlwbubKaoejiWLTsBY4HeqehQQ4KsmheYk/Tm7zR9TgEJgAJCF03zSVHv6nMNp6Ryjeu4dJSkUAYOCtvOArXGKJapEJA0nITynqq+4u3eISH/3eH9gp7u/PfwejgfOFZENwBycJqT7gR4i0rCSYPB5NZ6ze7w7ztKvyaQIKFLVhe72SzhJoj1/zqcB61V1l6rWAK8AE2nfn3OD1n6uUf28O0pSWAQMde9c6IzTYTU3zjG1mYgIzjrXq1T1N0GH5gINdyBcjtPX0LD/MvcuhmOBPQ2XqclCVW9T1TxVLcD5HP+lqt8G3gGmusWannPD72KqWz6pvkGq6nZgs4gc7u6aBHxGO/6ccZqNjhWRTPffecM5t9vPOUhrP9c3gMki0tO9wprs7otMvDtZYtiZczbwOfAl8MN4xxOlczoB5zLxU2CZ+3M2Tlvq28AX7mMvt7zg3IX1JbAc586OuJ9HG87/FGCe+/xQ4GNgLfAikO7uz3C317rHD4133BGe6xhgsftZ/xXo2d4/Z+BnwGpgBfAskN7ePmfgeZw+kxqcb/xXRfK5AtPdc18LXNmWmGxEszHGmEYdpfnIGGOMB5YUjDHGNLKkYIwxppElBWOMMY0sKRhjjGlkScHEjIioiPw6aPsmEflplOp+WkSmhi/Z5veZ5s5S+k6T/SnuDJYrRGS5iCwSkUL32Gsi0iNK718e5ngPEbkmaHuAiLwUjfc2HYMlBRNLVcB5ItI73oEEc2fR9eoq4BpV/VqT/RfgTMcwSlVHAt8EdgOo6tmqujsqwYbXA2hMCqq6VVV9T5am/bCkYGKpFmc5wRuaHmj6Tb/hG7GInCIi74rIn0XkcxG5U0S+LSIfu9/IBwdVc5qI/Nstd477+lQRucf95v6piFwdVO87IvInnIFATeO5yK1/hYjc5e77Mc6AwUdF5J4mL+kPbFPVegBVLVLVMvd1G0Skt4gUiLMewuNuvc+JyGki8r47D/4Et/xPReSmoFhWSJP1AUQkW0TeFpFP3DinuIfuBAaLyDL3vAvEnatfnPUInnLLLxWRr7n7rxCRV0TkdTeOu4N+d08HXf0c9LmZ9qdT+CLGRNXDwKcNf3g8Gg0Mx5nLZh3wuKpOEGdRoe8B17vlCoCTgcHAOyIyBLgMZzqAo0UkHXhfRP7plp8AjFDV9cFvJiIDcObjH4czZ/8/ReQbqnqHiJwK3KSqi5vE+GdggYiciDMK9Y+qurSZcxkCTMOZD38RcDFOojkXuB34hsffSSXwTVXd6155fSQic3EmyhuhqmPccykIes1MAFUdKSLD3PM6zD02BmeW3SpgjYg8hDM750B11jMgWk1gJrHZlYKJKXVmcf0DzgIqXi1S1W2qWoUzxL/hj/pynETQ4M+qWq+qX+Akj2E488BcJiLLcKYVz8FZpATg46YJwXU0MF+dydhqgeeAk8KcVxFwOM5aHfXA2yIyqZmi61V1uXtFsRJnMRVt5lzCEeCXIvIp8BbOVMl9w7zmBJzpIlDV1cBGoCEpvK2qe1S1EmeOoUNwfoeHishDInImEGoGXtNO2JWCiYf7gU+Ap4L21eJ+SXEnQOscdKwq6Hl90HY9B/4bbjpnS8O0wt9T1QMmCBORU3CmoG5Oc1MRh+UmrX8A/xCRHTjf+t9uUszLuTT+LlwZzbzdt4FcYJyq1ogza2xz5YKFOq/guOpwFrIpE5HROIvbzATOx5ljx7RjdqVgYk5VS3GaW64K2r0Bp7kGnHn00yKoepp7F9BgnInT1uDMFvldcaYYR0QOE2eBmlAWAie7/QCpOCtbvRvqBSIy1m12QkRSgFE438QjsQFnamzEWYe3sJky3XHWlahx+wYOcffvA7q2UO97OMkEt9koH+d31Cy3WSpFVV8G/rchJtO+2ZWCiZdfA9cGbT8G/E1EPsb5dt3St/hQ1uD88e4L/I+qVorI4zjNMp+4VyC7CNNur6rbROQ2nGmaBXhNVf8W6jU47e+Puf0W4MzU+dsIzgGc9TEamrwW4czu29RzwKsishhndtzVbuwlbsf1CpyrloeDXvMITif5cpyrkStUtcr5tTRrIM5qbw1fHm+L8HxMErFZUo0xxjSy5iNjjDGNLCkYY4xpZEnBGGNMI0sKxhhjGllSMMYY08iSgjHGmEaWFIwxxjSypGCMMabR/wMnV6Q2cxStjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_comparison(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RecurrentNN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "rnn.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model.save_weights('model.h5')\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(rnn.model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Model\", \"config\": {\"name\": \"model_157\", \"layers\": [{\"name\": \"input_166\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 7, 28], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_166\"}, \"inbound_nodes\": []}, {\"name\": \"lstm_154\", \"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_154\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"units\": 128, \"activation\": \"tanh\", \"recurrent_activation\": \"hard_sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.2, \"recurrent_dropout\": 0.2, \"implementation\": 1}, \"inbound_nodes\": [[[\"input_166\", 0, 0, {}]]]}, {\"name\": \"dense_224\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_224\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"lstm_154\", 0, 0, {}]]]}, {\"name\": \"pi\", \"class_name\": \"Dense\", \"config\": {\"name\": \"pi\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 7, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dense_224\", 0, 0, {}]]]}, {\"name\": \"v\", \"class_name\": \"Dense\", \"config\": {\"name\": \"v\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"inbound_nodes\": [[[\"dense_224\", 0, 0, {}]]]}], \"input_layers\": [[\"input_166\", 0, 0]], \"output_layers\": [[\"pi\", 0, 0], [\"v\", 0, 0]]}, \"keras_version\": \"2.1.6-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 1716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
